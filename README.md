# ğŸŒ Englishâ€“Tamil Neural Machine Translation (Encoderâ€“Decoder Transformer)

A custom-built encoderâ€“decoder Transformer model for Englishâ€“Tamil sentence-level machine translation.  
Trained from scratch on 11,000 Englishâ€“Tamil parallel sentence pairs using a custom word-level tokenizer.

---

## ğŸ“ Project Structure

This implementation is currently fully contained within a Jupyter Notebook for simplicity and transparency.  
The notebook walks through the entire pipeline â€” from tokenization and preprocessing to training and evaluation.

Python script files (`model.py`, `train.py`, etc.) have been scaffolded and will be populated to modularize the codebase for production-readiness.

> ğŸ”§ For now, please refer to the notebook for the complete working implementation.

---

## Features

- âœ… Custom-built encoderâ€“decoder Transformer architecture (from scratch)
- ğŸŒ Trained on 11,000 Englishâ€“Tamil parallel sentence pairs
- ğŸ”¡ Word-level tokenizer tailored for both English and Tamil scripts
- ğŸ§  ~4 million trainable parameters
- ğŸ—‚ï¸ Modular `.py` scripts planned (`model.py`, `train.py`, etc.)
- ğŸ–¥ï¸ Gradio-based demo interface planned for real-time translation
